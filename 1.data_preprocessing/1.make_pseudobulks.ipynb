{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook makes the Pseudobulks from processed single-cell data and formats relevant metadata\n",
    "\n",
    "Data format requirements for single-cell data:\n",
    "- processed data is not scaled\n",
    "- cells are filtered such that low-quality cells are removed (for example: filter out cells with less than 200 genes and genes expressed in less than 3 cells, and > 5% MT reads)\n",
    "- data is saved as an AnnData object and you have sample IDs, gene IDs, and cell-type labels\n",
    "\n",
    "The end product of this notebook will include the following `.pkl` files per each sample, stimulation and datasplit combination:\n",
    "- Pseudobulk gene expression (`*_pseudo_splits.pkl`) and proportions (`*_prop_splits.pkl`) from random cell type mixture and single cell type dominant mixture\n",
    "- Metadata (`*_meta_splits.pkl`) with the following fields\n",
    "  - the observations have columns named: \"sample_id\", \"stim\", \"isTraining\"\n",
    "  - sample_id: unique IDs for the samples\n",
    "  - stim: is \"STIM\" or \"CTRL\", denotes if the sample is \"female\" or \"male\"\n",
    "  - isTraining: 'Train' or 'Test',  denotes whether the sample is used during training or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import yaml\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE_COL = 'encode_celltype'\n",
    "SAMPLE_ID_COL = 'sample_id'\n",
    "STIM_COL = 'stim'\n",
    "\n",
    "GENE_ID_COL = 'gene_ids'\n",
    "\n",
    "DATASPLIT_COL = 'isTraining'\n",
    "\n",
    "DATASPLIT_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config\n",
    "The config file specifies the path to data and software repo (due to currently in active development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root directory of the analysis repository\n",
    "REPO_ROOT = subprocess.run(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "REPO_ROOT = pathlib.Path(REPO_ROOT)\n",
    "\n",
    "CONFIG_FILE = REPO_ROOT / 'config.yml'\n",
    "assert CONFIG_FILE.exists(), f\"Config file not found at {CONFIG_FILE}\"\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as file:\n",
    "    config_dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dev buddi fork to path and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buddi_fork_path = config_dict['software_path']['buddi_HGSC']\n",
    "buddi_fork_path = pathlib.Path(buddi_fork_path)\n",
    "assert buddi_fork_path.exists(), f\"buddi fork not found at {buddi_fork_path}\"\n",
    "\n",
    "sys.path.insert(0, str(buddi_fork_path))\n",
    "# this is quite ugly, once activate modifications are done this will be changed\n",
    "# to a proper installation + import\n",
    "from buddi import preprocessing\n",
    "from buddi.preprocessing import utils\n",
    "from buddi.preprocessing import generate_pseudo_bulks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Path to Processed Single-Cell RNA-seq Data and relevant Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_GEO_ID = 'GSE154600' # TODO consider whether to move this into config.yml as well\n",
    "SC_DATA_PATH = pathlib.Path(config_dict['data_path']['sc_data_path'])\n",
    "\n",
    "SC_ADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_processed'\n",
    "assert SC_ADATA_PATH.exists(), f\"Processed Single-cell Data path {SC_ADATA_PATH} does not exist\"\n",
    "SC_ADATA_FILE = SC_ADATA_PATH / f'{STUDY_GEO_ID}_processed.h5ad'\n",
    "assert SC_ADATA_FILE.exists(), f\"Processed Single-cell Data file {SC_ADATA_FILE} does not exist\"\n",
    "\n",
    "SC_METADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_metadata'\n",
    "assert SC_METADATA_PATH.exists(), f\"Single-cell Metadata path {SC_METADATA_PATH} does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path to write Pre-Processing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_OUTPUT_PATH = REPO_ROOT / 'processed_data'\n",
    "assert PREPROCESSING_OUTPUT_PATH.exists(), f\"Preprocessing output path {PREPROCESSING_OUTPUT_PATH} does not exist\"\n",
    "SC_AUGMENTED_DATA_PATH = PREPROCESSING_OUTPUT_PATH / 'sc_augmented'\n",
    "SC_AUGMENTED_DATA_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of scRNA-seq Anndata before Moving to Pseudobulk\n",
    "### Load and Preprocess Anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(SC_ADATA_FILE)\n",
    "\n",
    "# checking if the defined columns are present in the adata.obs\n",
    "assert CELL_TYPE_COL in adata.obs.columns, f\"Column {CELL_TYPE_COL} not found in adata.obs\"\n",
    "assert SAMPLE_ID_COL in adata.obs.columns, f\"Column {SAMPLE_ID_COL} not found in adata.obs\"\n",
    "assert STIM_COL in adata.obs.columns, f\"Column {STIM_COL} not found in adata.obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()\n",
    "adata.var[GENE_ID_COL] = adata.var.index.tolist()\n",
    "\n",
    "# replace underscores with hyphens in the sample_id column\n",
    "adata.obs[SAMPLE_ID_COL] = adata.obs[SAMPLE_ID_COL].str.replace('_', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36111, 24520)\n",
      "              gene_ids  n_cells     mt  n_cells_by_counts  mean_counts  \\\n",
      "gene_ids                                                                 \n",
      "AL627309.1  AL627309.1       23  False                 23     0.000614   \n",
      "AL669831.5  AL669831.5      629  False                629     0.017388   \n",
      "FAM87B          FAM87B       26  False                 26     0.000694   \n",
      "LINC00115    LINC00115      463  False                463     0.012661   \n",
      "FAM41C          FAM41C      279  False                279     0.007746   \n",
      "\n",
      "            pct_dropout_by_counts  total_counts  \n",
      "gene_ids                                         \n",
      "AL627309.1              99.938567          23.0  \n",
      "AL669831.5              98.319934         651.0  \n",
      "FAM87B                  99.930554          26.0  \n",
      "LINC00115               98.763322         474.0  \n",
      "FAM41C                  99.254788         290.0  \n",
      "                           GSM             Barcode  Cluster          cellType  \\\n",
      "AAACCTGAGCTGCCCA-1  GSM4675273  AAACCTGAGCTGCCCA-1        3       Macrophages   \n",
      "AAACCTGCAAGCCCAC-1  GSM4675273  AAACCTGCAAGCCCAC-1        3       Macrophages   \n",
      "AAACCTGCAAGCGCTC-1  GSM4675273  AAACCTGCAAGCGCTC-1        5  Epithelial cells   \n",
      "AAACCTGCACGTAAGG-1  GSM4675273  AAACCTGCACGTAAGG-1        5  Epithelial cells   \n",
      "AAACCTGCACGTGAGA-1  GSM4675273  AAACCTGCACGTGAGA-1        3         Monocytes   \n",
      "\n",
      "                       hpca_celltype   encode_celltype subtype  IMR_consensus  \\\n",
      "AAACCTGAGCTGCCCA-1        Macrophage       Macrophages     DIF          0.322   \n",
      "AAACCTGCAAGCCCAC-1        Macrophage       Macrophages     IMR          0.362   \n",
      "AAACCTGCAAGCGCTC-1  Epithelial_cells  Epithelial cells     DIF          0.228   \n",
      "AAACCTGCACGTAAGG-1  Epithelial_cells  Epithelial cells     DIF          0.176   \n",
      "AAACCTGCACGTGAGA-1        Macrophage         Monocytes     DIF          0.256   \n",
      "\n",
      "                    DIF_consensus  PRO_consensus  ...  celltype_granular  \\\n",
      "AAACCTGAGCTGCCCA-1          0.334          0.158  ...             immune   \n",
      "AAACCTGCAAGCCCAC-1          0.248          0.142  ...             immune   \n",
      "AAACCTGCAAGCGCTC-1          0.346          0.266  ...              tumor   \n",
      "AAACCTGCACGTAAGG-1          0.494          0.258  ...              tumor   \n",
      "AAACCTGCACGTGAGA-1          0.304          0.192  ...             immune   \n",
      "\n",
      "                     scpred_CellType  orig_celltype sample_id  stim n_genes  \\\n",
      "AAACCTGAGCTGCCCA-1       Macrophages            MYE  Samp-T59  CTRL     805   \n",
      "AAACCTGCAAGCCCAC-1       Macrophages            MYE  Samp-T59  CTRL    1044   \n",
      "AAACCTGCAAGCGCTC-1  Epithelial cells            EPI  Samp-T59  CTRL    2608   \n",
      "AAACCTGCACGTAAGG-1  Epithelial cells            EPI  Samp-T59  CTRL    3468   \n",
      "AAACCTGCACGTGAGA-1         Monocytes            MYE  Samp-T59  CTRL    1684   \n",
      "\n",
      "                   n_genes_by_counts  total_counts total_counts_mt  \\\n",
      "AAACCTGAGCTGCCCA-1               805        1580.0            92.0   \n",
      "AAACCTGCAAGCCCAC-1              1044        2177.0            72.0   \n",
      "AAACCTGCAAGCGCTC-1              2608        6224.0           314.0   \n",
      "AAACCTGCACGTAAGG-1              3468        8744.0           182.0   \n",
      "AAACCTGCACGTGAGA-1              1684        4395.0           193.0   \n",
      "\n",
      "                   pct_counts_mt  \n",
      "AAACCTGAGCTGCCCA-1      5.822785  \n",
      "AAACCTGCAAGCCCAC-1      3.307304  \n",
      "AAACCTGCAAGCGCTC-1      5.044987  \n",
      "AAACCTGCACGTAAGG-1      2.081427  \n",
      "AAACCTGCACGTGAGA-1      4.391354  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adata.shape)\n",
    "print(adata.var.head())\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "sample_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CTRL",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "77ff031e-2795-4441-b475-98653186773c",
       "rows": [
        [
         "Samp-T59",
         "11689"
        ],
        [
         "Samp-T76",
         "11876"
        ],
        [
         "Samp-T77",
         "4974"
        ],
        [
         "Samp-T89",
         "4291"
        ],
        [
         "Samp-T90",
         "3281"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stim</th>\n",
       "      <th>CTRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Samp-T59</th>\n",
       "      <td>11689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T76</th>\n",
       "      <td>11876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T77</th>\n",
       "      <td>4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T89</th>\n",
       "      <td>4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T90</th>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stim        CTRL\n",
       "sample_id       \n",
       "Samp-T59   11689\n",
       "Samp-T76   11876\n",
       "Samp-T77    4974\n",
       "Samp-T89    4291\n",
       "Samp-T90    3281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = adata.obs.groupby([SAMPLE_ID_COL, STIM_COL]).size()\n",
    "tab.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CD8+ T-cells         8183\n",
       "Fibroblasts          4385\n",
       "Epithelial cells     4021\n",
       "Macrophages          3979\n",
       "Adipocytes           3955\n",
       "Monocytes            3507\n",
       "Mesangial cells      3488\n",
       "CD4+ T-cells         1476\n",
       "NK cells             1409\n",
       "B-cells              1169\n",
       "Endothelial cells     539\n",
       "Name: encode_celltype, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs[CELL_TYPE_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Gene ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_out_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_genes.pkl'\n",
    "gene_ids = adata.var[GENE_ID_COL]\n",
    "pickle.dump(gene_ids, open( gene_out_file, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pseudobulks\n",
    "### First perform random train test split stratifying by sample id and stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_idx, test_idx = train_test_split(\n",
    "    adata.obs.index,\n",
    "    test_size=0.2,\n",
    "    stratify=adata.obs[[SAMPLE_ID_COL, STIM_COL, CELL_TYPE_COL]],\n",
    "    random_state=DATASPLIT_SEED\n",
    ")\n",
    "\n",
    "# Assign the split to the DATASPLIT_COL\n",
    "adata.obs.loc[train_idx, DATASPLIT_COL] = 'Train'\n",
    "adata.obs.loc[test_idx, DATASPLIT_COL] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pseudo-bulk profiles for sample Samp-T59, stim CTRL, and datasplit Train ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T59, stim CTRL, and datasplit Test ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T76, stim CTRL, and datasplit Train ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T76, stim CTRL, and datasplit Test ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T77, stim CTRL, and datasplit Train ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T77, stim CTRL, and datasplit Test ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T89, stim CTRL, and datasplit Train ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T89, stim CTRL, and datasplit Test ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T90, stim CTRL, and datasplit Train ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T90, stim CTRL, and datasplit Test ...\n",
      "\tGenerating random prop pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "\tGenerating single cell dominant pseudo-bulk profiles ...\n",
      "Processing sample 0\n",
      "Processing sample 100\n",
      "Processing sample 200\n",
      "Processing sample 300\n",
      "Processing sample 400\n",
      "Processing sample 500\n",
      "Processing sample 600\n",
      "Processing sample 700\n",
      "Processing sample 800\n",
      "Processing sample 900\n",
      "Processing sample 1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n"
     ]
    }
   ],
   "source": [
    "ADD_PER_CELL_TYPE_NOISE = True\n",
    "N_CELLS_PER_PSEUDO_BULK = 5_000\n",
    "N_PSEUDO_BULKS_PER_CONDITION = 1_000\n",
    "\n",
    "gene_ids = adata.var[GENE_ID_COL]\n",
    "samples = adata.obs[SAMPLE_ID_COL].unique()\n",
    "stims = adata.obs[STIM_COL].unique()\n",
    "\n",
    "## Global cell types\n",
    "cell_types = adata.obs[CELL_TYPE_COL].unique()\n",
    "cell_order = sorted(cell_types) # format the proportion columns in the same order\n",
    "datasplits = adata.obs[DATASPLIT_COL].unique()\n",
    "\n",
    "n_samples = len(samples)\n",
    "n_genes = len(gene_ids)\n",
    "n_cell_types = len(cell_order)\n",
    "\n",
    "# Define cell-type level noise for the generated pseudo-bulk profiles\n",
    "if ADD_PER_CELL_TYPE_NOISE:\n",
    "    # this produces a list of numpy arrays, each of length n_genes\n",
    "    # to reflect the expression noise associated with each specific cell type\n",
    "    per_cell_type_noise = [\n",
    "        np.random.lognormal(0, 0, n_genes) for i in range(n_cell_types)]\n",
    "else:\n",
    "    per_cell_type_noise = None\n",
    "\n",
    "# Generate pseudo-bulk profiles grouping by sample_id and stim\n",
    "for _sample in samples:\n",
    "    for _stim in stims:\n",
    "        for _datasplit in datasplits:\n",
    "\n",
    "            print(f\"Generating pseudo-bulk profiles for sample {_sample}, stim {_stim}, and datasplit {_datasplit} ...\")\n",
    "            \n",
    "            ## Subset adata to the current sample, stim and train/test split\n",
    "            subset_idx = np.where(\n",
    "                np.logical_and.reduce((\n",
    "                    adata.obs[SAMPLE_ID_COL] == _sample, \n",
    "                    adata.obs[STIM_COL] == _stim,\n",
    "                    adata.obs[DATASPLIT_COL] == _datasplit\n",
    "                ))\n",
    "            )[0]\n",
    "            \n",
    "            if len(subset_idx) == 0:\n",
    "                continue\n",
    "            subset_adata = adata[subset_idx, :]\n",
    "\n",
    "            ## Cell type that is present in the subset, will inform the \n",
    "            ## down stream workflow of potential missing cell types to skip\n",
    "            present_cell_types = subset_adata.obs[CELL_TYPE_COL].unique().to_list()\n",
    "\n",
    "            ## Subset the cell_df to the present cell types\n",
    "            cell_df = preprocessing.utils.subset_adata_by_cell_type(\n",
    "                subset_adata, \n",
    "                cell_type_col=CELL_TYPE_COL,\n",
    "                cell_order=cell_order\n",
    "            )\n",
    "\n",
    "            print(\"\\tGenerating random prop pseudo-bulk profiles ...\")\n",
    "\n",
    "            random_count_df = preprocessing.utils.generate_log_normal_counts(\n",
    "                cell_order=cell_order, \n",
    "                num_cells=N_CELLS_PER_PSEUDO_BULK, \n",
    "                num_samples=N_PSEUDO_BULKS_PER_CONDITION,\n",
    "                present_cell_types=present_cell_types\n",
    "            )\n",
    "            random_props_df = preprocessing.utils.generate_prop_from_counts(\n",
    "                random_count_df,\n",
    "            )\n",
    "            random_pseudobulk_df = preprocessing.generate_pseudo_bulks.generate_pseudo_bulk_from_counts(\n",
    "                in_adata=subset_adata,\n",
    "                cell_df=cell_df,\n",
    "                count_df=random_count_df,\n",
    "                cell_noise=per_cell_type_noise,\n",
    "                use_sample_noise=False\n",
    "            )\n",
    "\n",
    "            print(\"\\tGenerating single cell dominant pseudo-bulk profiles ...\")\n",
    "\n",
    "            single_cell_props_df = preprocessing.utils.generate_single_celltype_dominant_props(\n",
    "                num_samp=100,\n",
    "                cell_order=cell_order,\n",
    "                present_cell_types=present_cell_types\n",
    "            )\n",
    "            single_cell_counts_df = preprocessing.utils.generate_counts_from_props(\n",
    "                single_cell_props_df,\n",
    "                num_cells=N_CELLS_PER_PSEUDO_BULK\n",
    "            )\n",
    "            single_cell_pseudobulk_df = preprocessing.generate_pseudo_bulks.generate_pseudo_bulk_from_counts(\n",
    "                in_adata=subset_adata,\n",
    "                cell_df=cell_df,\n",
    "                count_df=single_cell_counts_df,\n",
    "                cell_noise=per_cell_type_noise,\n",
    "                use_sample_noise=False\n",
    "            )\n",
    "\n",
    "            print('Concatenating the two types of pseudo-bulk profiles ...')\n",
    "            props_df = pd.concat([random_props_df, single_cell_props_df])\n",
    "            pseudobulk_df = pd.concat([random_pseudobulk_df, single_cell_pseudobulk_df])\n",
    "\n",
    "            ## Metadata assembly            \n",
    "            n_random_prop_pbs = len(random_props_df)\n",
    "            n_single_celltype_pbs = len(single_cell_pseudobulk_df)\n",
    "            n_total_pbs = n_random_prop_pbs + n_single_celltype_pbs\n",
    "\n",
    "            metadata_df = pd.DataFrame(\n",
    "                data = {\"sample_id\":[_sample]*n_total_pbs,\n",
    "                        \"stim\":[_stim]*n_total_pbs,\n",
    "                        \"isTraining\":[_datasplit]*n_total_pbs,\n",
    "                        \"cell_prop_type\":['random']*n_random_prop_pbs + ['single_celltype']*n_single_celltype_pbs,\n",
    "                        \"samp_type\":['sc_ref']*n_total_pbs}\n",
    "                        )\n",
    "            \n",
    "            print(\"Writing the pseudo-bulk profiles ...\")\n",
    "            pseudobulk_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_pseudo_splits.pkl'\n",
    "            prop_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_prop_splits.pkl'\n",
    "            meta_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_meta_splits.pkl'\n",
    "\n",
    "            pickle.dump( props_df, open( prop_file, \"wb\" ) )\n",
    "            pickle.dump( pseudobulk_df, open( pseudobulk_file, \"wb\" ) )\n",
    "            pickle.dump( metadata_df, open( meta_file, \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buddi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
