{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook ... TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import yaml\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "from buddi.preprocessing import sc_preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO consider whether to move these into config.yml\n",
    "CELL_TYPE_COL = 'cellType'\n",
    "SAMPLE_ID_COL = 'sample_id'\n",
    "STIM_COL = 'stim'\n",
    "\n",
    "GENE_ID_COL = 'gene_ids'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root directory of the analysis repository\n",
    "REPO_ROOT = subprocess.run(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "REPO_ROOT = pathlib.Path(REPO_ROOT)\n",
    "\n",
    "CONFIG_FILE = REPO_ROOT / 'config.yml'\n",
    "assert CONFIG_FILE.exists(), f\"Config file not found at {CONFIG_FILE}\"\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as file:\n",
    "    config_dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Path to Processed Single-Cell RNA-seq Data and relevant Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_GEO_ID = 'GSE154600' # TODO consider whether to move this into config.yml as well\n",
    "SC_DATA_PATH = pathlib.Path(config_dict['data_path']['sc_data_path'])\n",
    "\n",
    "SC_ADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_processed'\n",
    "assert SC_ADATA_PATH.exists(), f\"Processed Single-cell Data path {SC_ADATA_PATH} does not exist\"\n",
    "SC_ADATA_FILE = SC_ADATA_PATH / f'{STUDY_GEO_ID}_processed.h5ad'\n",
    "assert SC_ADATA_FILE.exists(), f\"Processed Single-cell Data file {SC_ADATA_FILE} does not exist\"\n",
    "\n",
    "SC_METADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_metadata'\n",
    "assert SC_METADATA_PATH.exists(), f\"Single-cell Metadata path {SC_METADATA_PATH} does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path to write Pre-Processing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_OUTPUT_PATH = REPO_ROOT / 'processed_data'\n",
    "assert PREPROCESSING_OUTPUT_PATH.exists(), f\"Preprocessing output path {PREPROCESSING_OUTPUT_PATH} does not exist\"\n",
    "SC_AUGMENTED_DATA_PATH = PREPROCESSING_OUTPUT_PATH / 'sc_augmented'\n",
    "SC_AUGMENTED_DATA_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of scRNA-seq Anndata before Moving to Pseudobulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(SC_ADATA_FILE)\n",
    "adata.var_names_make_unique()\n",
    "adata.var[GENE_ID_COL] = adata.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the defined columns are present in the adata.obs\n",
    "assert CELL_TYPE_COL in adata.obs.columns, f\"Column {CELL_TYPE_COL} not found in adata.obs\"\n",
    "assert SAMPLE_ID_COL in adata.obs.columns, f\"Column {SAMPLE_ID_COL} not found in adata.obs\"\n",
    "assert STIM_COL in adata.obs.columns, f\"Column {STIM_COL} not found in adata.obs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.shape)\n",
    "print(adata.var.head())\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = adata.obs.groupby([SAMPLE_ID_COL, STIM_COL]).size()\n",
    "tab.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[CELL_TYPE_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Dense Expression Matrix and Celltype column to use in CIBERSORTx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_profile_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_sig.pkl'\n",
    "\n",
    "dense_matrix = adata.X.todense()\n",
    "dense_df = pd.DataFrame(dense_matrix, columns = adata.var[GENE_ID_COL])\n",
    "dense_df.insert(loc=0, column=CELL_TYPE_COL, value=adata.obs[CELL_TYPE_COL].to_list())\n",
    "\n",
    "pickle.dump( dense_df, open( sc_profile_file, \"wb\" ) )\n",
    "\n",
    "# free up memory\n",
    "del dense_matrix\n",
    "del dense_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pseudobulks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_out_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_genes.pkl'\n",
    "gene_ids = adata.var[GENE_ID_COL]\n",
    "pickle.dump(gene_ids, open( gene_out_file, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_PER_CELL_TYPE_NOISE = True\n",
    "N_CELLS_PER_PSEUDO_BULK = 5_000\n",
    "N_PSEUDO_BULKS_PER_CONDITION = 1_000\n",
    "\n",
    "# Unique values for experiment/perturbation/cell type\n",
    "samples = adata.obs[SAMPLE_ID_COL].unique()\n",
    "stims = adata.obs[STIM_COL].unique()\n",
    "cell_types = adata.obs[CELL_TYPE_COL].unique()\n",
    "\n",
    "n_samples = len(samples)\n",
    "n_genes = len(gene_ids)\n",
    "n_cell_types = len(cell_types)\n",
    "\n",
    "# Define cell-type level noise for the generated pseudo-bulk profiles\n",
    "if ADD_PER_CELL_TYPE_NOISE:\n",
    "    # this produces a list of numpy arrays, each of length n_genes\n",
    "    # to reflect the expression noise associated with each specific cell type\n",
    "    per_cell_type_noise = [\n",
    "        np.random.lognormal(0, 0, n_genes) for i in range(n_cell_types)]\n",
    "else:\n",
    "    per_cell_type_noise = None\n",
    "\n",
    "# Generate pseudo-bulk profiles grouping by sample_id and stim\n",
    "for _sample in samples:\n",
    "    for _stim in stims:\n",
    "\n",
    "        print(f\"Generating pseudo-bulk profiles for sample {_sample} and stim {_stim}\")\n",
    "\n",
    "        ## Subset adata to the current sample and stim\n",
    "        subset_idx = np.logical_and(\n",
    "            adata.obs[SAMPLE_ID_COL] == _sample, \n",
    "            adata.obs[STIM_COL] == _stim\n",
    "            )\n",
    "        if len(subset_idx) == 0:\n",
    "            continue\n",
    "        subset_adata = adata[subset_idx, :]\n",
    "\n",
    "        print(\"Generating random prop pseudo-bulk profiles ...\")\n",
    "        random_prop_pb_outputs = sc_preprocess.make_prop_and_sum(\n",
    "            in_adata=subset_adata,\n",
    "            # the number of pseudo-bulk profiles to generate\n",
    "            num_samples=N_PSEUDO_BULKS_PER_CONDITION,\n",
    "            # the number of cells included/sampled when generating each pseudo-bulk profile\n",
    "            num_cells=N_CELLS_PER_PSEUDO_BULK,\n",
    "            # pseudo-bulk profiles will be generated with random proportions\n",
    "            use_true_prop=False,\n",
    "            # apply the per cell type noise\n",
    "            cell_noise=per_cell_type_noise,\n",
    "            # no sample noise\n",
    "            useSampleNoise=False,\n",
    "        )\n",
    "\n",
    "        count_df, pb_df, test_count_df, test_pb_df = random_prop_pb_outputs\n",
    "        # divide the count matrix by the sum of each row to get proportions\n",
    "        prop_df = count_df.div(count_df.sum(axis=1), axis=0)\n",
    "        test_prop_df = test_count_df.div(test_count_df.sum(axis=1), axis=0)\n",
    "\n",
    "        del count_df\n",
    "        del test_count_df\n",
    "\n",
    "        n_random_prop_pbs = len(pb_df)\n",
    "\n",
    "        print(\"Generating single cell type dominant pseudo-bulk profiles ...\")\n",
    "\n",
    "        # Generate pseudo-bulk profiles where a single cell type dominates\n",
    "        # this will produce num_samp * n_cell_types pseudo-bulk profiles\n",
    "        ct_prop_df = sc_preprocess.get_single_celltype_prop_matrix(\n",
    "            num_samp=100, #  generate 100 per cell type\n",
    "            cell_order=cell_types\n",
    "        )\n",
    "\n",
    "        # Use proportion matrix to generate pseudo-bulk profiles\n",
    "        sc_prop_df, sc_pb_df, _ = sc_preprocess.use_prop_make_sum(\n",
    "            in_adata=subset_adata,\n",
    "            num_cells=N_CELLS_PER_PSEUDO_BULK,\n",
    "            # use the generated single cell type dominant proportion matrix\n",
    "            props_vec=ct_prop_df,\n",
    "            # apply the same per cell type noise used for random prop pseudo-bulk profiles\n",
    "            cell_noise=per_cell_type_noise,\n",
    "            # no sample noise\n",
    "            sample_noise=None,\n",
    "            useSampleNoise=False\n",
    "        )\n",
    "\n",
    "        n_single_celltype_pbs = len(sc_pb_df)\n",
    "\n",
    "        print('Concatenating the two types of pseudo-bulk profiles ...')\n",
    "        prop_df =  pd.concat([prop_df, sc_prop_df])\n",
    "        pb_df = pd.concat([pb_df, sc_pb_df])\n",
    "\n",
    "        n_total_pbs = n_random_prop_pbs + n_single_celltype_pbs\n",
    "\n",
    "        metadata_df = pd.DataFrame(\n",
    "            data = {\"sample_id\":[_sample]*n_total_pbs,\n",
    "                    \"stim\":[_stim]*n_total_pbs,\n",
    "                    \"cell_prop_type\":['random']*n_random_prop_pbs + ['single_celltype']*n_single_celltype_pbs,\n",
    "                    \"samp_type\":['sc_ref']*n_total_pbs}\n",
    "                    )\n",
    "        \n",
    "        print(\"Writing the pseudo-bulk profiles ...\")\n",
    "        pseudobulk_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_pseudo_splits.pkl'\n",
    "        prop_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_prop_splits.pkl'\n",
    "        meta_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_meta_splits.pkl'\n",
    "\n",
    "        pickle.dump( prop_df, open( prop_file, \"wb\" ) )\n",
    "        pickle.dump( pb_df, open( pseudobulk_file, \"wb\" ) )\n",
    "        pickle.dump( metadata_df, open( meta_file, \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buddi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
