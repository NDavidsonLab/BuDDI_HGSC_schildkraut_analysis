{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook ... TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import yaml\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from buddi.preprocessing import sc_preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO consider whether to move these into config.yml\n",
    "CELL_TYPE_COL = 'scpred_CellType'\n",
    "SAMPLE_ID_COL = 'sample_id'\n",
    "STIM_COL = 'stim'\n",
    "\n",
    "GENE_ID_COL = 'gene_ids'\n",
    "\n",
    "DATASPLIT_COL = 'isTraining'\n",
    "\n",
    "DATASPLIT_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root directory of the analysis repository\n",
    "REPO_ROOT = subprocess.run(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "REPO_ROOT = pathlib.Path(REPO_ROOT)\n",
    "\n",
    "CONFIG_FILE = REPO_ROOT / 'config.yml'\n",
    "assert CONFIG_FILE.exists(), f\"Config file not found at {CONFIG_FILE}\"\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as file:\n",
    "    config_dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Path to Processed Single-Cell RNA-seq Data and relevant Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_GEO_ID = 'GSE154600' # TODO consider whether to move this into config.yml as well\n",
    "SC_DATA_PATH = pathlib.Path(config_dict['data_path']['sc_data_path'])\n",
    "\n",
    "SC_ADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_processed'\n",
    "assert SC_ADATA_PATH.exists(), f\"Processed Single-cell Data path {SC_ADATA_PATH} does not exist\"\n",
    "SC_ADATA_FILE = SC_ADATA_PATH / f'{STUDY_GEO_ID}_processed.h5ad'\n",
    "assert SC_ADATA_FILE.exists(), f\"Processed Single-cell Data file {SC_ADATA_FILE} does not exist\"\n",
    "\n",
    "SC_METADATA_PATH = SC_DATA_PATH / f'{STUDY_GEO_ID}_metadata'\n",
    "assert SC_METADATA_PATH.exists(), f\"Single-cell Metadata path {SC_METADATA_PATH} does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path to write Pre-Processing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_OUTPUT_PATH = REPO_ROOT / 'processed_data'\n",
    "assert PREPROCESSING_OUTPUT_PATH.exists(), f\"Preprocessing output path {PREPROCESSING_OUTPUT_PATH} does not exist\"\n",
    "SC_AUGMENTED_DATA_PATH = PREPROCESSING_OUTPUT_PATH / 'sc_augmented'\n",
    "SC_AUGMENTED_DATA_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of scRNA-seq Anndata before Moving to Pseudobulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(SC_ADATA_FILE)\n",
    "\n",
    "# checking if the defined columns are present in the adata.obs\n",
    "assert CELL_TYPE_COL in adata.obs.columns, f\"Column {CELL_TYPE_COL} not found in adata.obs\"\n",
    "assert SAMPLE_ID_COL in adata.obs.columns, f\"Column {SAMPLE_ID_COL} not found in adata.obs\"\n",
    "assert STIM_COL in adata.obs.columns, f\"Column {STIM_COL} not found in adata.obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()\n",
    "adata.var[GENE_ID_COL] = adata.var.index.tolist()\n",
    "\n",
    "# replace underscores with hyphens in the sample_id column\n",
    "adata.obs[SAMPLE_ID_COL] = adata.obs[SAMPLE_ID_COL].str.replace('_', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36111, 24520)\n",
      "              gene_ids  n_cells     mt  n_cells_by_counts  mean_counts  \\\n",
      "gene_ids                                                                 \n",
      "AL627309.1  AL627309.1       23  False                 23     0.000614   \n",
      "AL669831.5  AL669831.5      629  False                629     0.017388   \n",
      "FAM87B          FAM87B       26  False                 26     0.000694   \n",
      "LINC00115    LINC00115      463  False                463     0.012661   \n",
      "FAM41C          FAM41C      279  False                279     0.007746   \n",
      "\n",
      "            pct_dropout_by_counts  total_counts  \n",
      "gene_ids                                         \n",
      "AL627309.1              99.938567          23.0  \n",
      "AL669831.5              98.319934         651.0  \n",
      "FAM87B                  99.930554          26.0  \n",
      "LINC00115               98.763322         474.0  \n",
      "FAM41C                  99.254788         290.0  \n",
      "                           GSM             Barcode  Cluster          cellType  \\\n",
      "AAACCTGAGCTGCCCA-1  GSM4675273  AAACCTGAGCTGCCCA-1        3       Macrophages   \n",
      "AAACCTGCAAGCCCAC-1  GSM4675273  AAACCTGCAAGCCCAC-1        3       Macrophages   \n",
      "AAACCTGCAAGCGCTC-1  GSM4675273  AAACCTGCAAGCGCTC-1        5  Epithelial cells   \n",
      "AAACCTGCACGTAAGG-1  GSM4675273  AAACCTGCACGTAAGG-1        5  Epithelial cells   \n",
      "AAACCTGCACGTGAGA-1  GSM4675273  AAACCTGCACGTGAGA-1        3         Monocytes   \n",
      "\n",
      "                       hpca_celltype   encode_celltype subtype  IMR_consensus  \\\n",
      "AAACCTGAGCTGCCCA-1        Macrophage       Macrophages     DIF          0.322   \n",
      "AAACCTGCAAGCCCAC-1        Macrophage       Macrophages     IMR          0.362   \n",
      "AAACCTGCAAGCGCTC-1  Epithelial_cells  Epithelial cells     DIF          0.228   \n",
      "AAACCTGCACGTAAGG-1  Epithelial_cells  Epithelial cells     DIF          0.176   \n",
      "AAACCTGCACGTGAGA-1        Macrophage         Monocytes     DIF          0.256   \n",
      "\n",
      "                    DIF_consensus  PRO_consensus  ...  celltype_granular  \\\n",
      "AAACCTGAGCTGCCCA-1          0.334          0.158  ...             immune   \n",
      "AAACCTGCAAGCCCAC-1          0.248          0.142  ...             immune   \n",
      "AAACCTGCAAGCGCTC-1          0.346          0.266  ...              tumor   \n",
      "AAACCTGCACGTAAGG-1          0.494          0.258  ...              tumor   \n",
      "AAACCTGCACGTGAGA-1          0.304          0.192  ...             immune   \n",
      "\n",
      "                     scpred_CellType  orig_celltype sample_id  stim n_genes  \\\n",
      "AAACCTGAGCTGCCCA-1       Macrophages            MYE  Samp-T59  CTRL     805   \n",
      "AAACCTGCAAGCCCAC-1       Macrophages            MYE  Samp-T59  CTRL    1044   \n",
      "AAACCTGCAAGCGCTC-1  Epithelial cells            EPI  Samp-T59  CTRL    2608   \n",
      "AAACCTGCACGTAAGG-1  Epithelial cells            EPI  Samp-T59  CTRL    3468   \n",
      "AAACCTGCACGTGAGA-1         Monocytes            MYE  Samp-T59  CTRL    1684   \n",
      "\n",
      "                   n_genes_by_counts  total_counts total_counts_mt  \\\n",
      "AAACCTGAGCTGCCCA-1               805        1580.0            92.0   \n",
      "AAACCTGCAAGCCCAC-1              1044        2177.0            72.0   \n",
      "AAACCTGCAAGCGCTC-1              2608        6224.0           314.0   \n",
      "AAACCTGCACGTAAGG-1              3468        8744.0           182.0   \n",
      "AAACCTGCACGTGAGA-1              1684        4395.0           193.0   \n",
      "\n",
      "                   pct_counts_mt  \n",
      "AAACCTGAGCTGCCCA-1      5.822785  \n",
      "AAACCTGCAAGCCCAC-1      3.307304  \n",
      "AAACCTGCAAGCGCTC-1      5.044987  \n",
      "AAACCTGCACGTAAGG-1      2.081427  \n",
      "AAACCTGCACGTGAGA-1      4.391354  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adata.shape)\n",
    "print(adata.var.head())\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "sample_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CTRL",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fb289ca8-86af-4429-b8ac-f05437e918bd",
       "rows": [
        [
         "Samp-T59",
         "11689"
        ],
        [
         "Samp-T76",
         "11876"
        ],
        [
         "Samp-T77",
         "4974"
        ],
        [
         "Samp-T89",
         "4291"
        ],
        [
         "Samp-T90",
         "3281"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stim</th>\n",
       "      <th>CTRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Samp-T59</th>\n",
       "      <td>11689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T76</th>\n",
       "      <td>11876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T77</th>\n",
       "      <td>4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T89</th>\n",
       "      <td>4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samp-T90</th>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stim        CTRL\n",
       "sample_id       \n",
       "Samp-T59   11689\n",
       "Samp-T76   11876\n",
       "Samp-T77    4974\n",
       "Samp-T89    4291\n",
       "Samp-T90    3281"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = adata.obs.groupby([SAMPLE_ID_COL, STIM_COL]).size()\n",
    "tab.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CD8+ T-cells         8183\n",
       "Fibroblasts          4385\n",
       "Epithelial cells     4021\n",
       "Macrophages          3979\n",
       "Adipocytes           3955\n",
       "Monocytes            3507\n",
       "Mesangial cells      3488\n",
       "CD4+ T-cells         1476\n",
       "NK cells             1409\n",
       "B-cells              1169\n",
       "Endothelial cells     539\n",
       "Name: scpred_CellType, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs[CELL_TYPE_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Dense Expression Matrix and Celltype column to use in CIBERSORTx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_profile_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_sig.pkl'\n",
    "\n",
    "dense_matrix = adata.X.todense()\n",
    "dense_df = pd.DataFrame(dense_matrix, columns = adata.var[GENE_ID_COL])\n",
    "dense_df.insert(loc=0, column=CELL_TYPE_COL, value=adata.obs[CELL_TYPE_COL].to_list())\n",
    "\n",
    "pickle.dump( dense_df, open( sc_profile_file, \"wb\" ) )\n",
    "\n",
    "# free up memory\n",
    "del dense_matrix\n",
    "del dense_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Gene ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_out_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_genes.pkl'\n",
    "gene_ids = adata.var[GENE_ID_COL]\n",
    "pickle.dump(gene_ids, open( gene_out_file, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pseudobulks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First perform random train test split stratifying by sample id and stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_idx, test_idx = train_test_split(\n",
    "    adata.obs.index,\n",
    "    test_size=0.2,\n",
    "    stratify=adata.obs[[SAMPLE_ID_COL, STIM_COL, CELL_TYPE_COL]],\n",
    "    random_state=DATASPLIT_SEED\n",
    ")\n",
    "\n",
    "# Assign the split to the DATASPLIT_COL\n",
    "adata.obs.loc[train_idx, DATASPLIT_COL] = 'Train'\n",
    "adata.obs.loc[test_idx, DATASPLIT_COL] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pseudo-bulk profiles for sample Samp-T59, stim CTRL, and datasplit Train ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T59, stim CTRL, and datasplit Test ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T76, stim CTRL, and datasplit Train ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T76, stim CTRL, and datasplit Test ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T77, stim CTRL, and datasplit Train ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T77, stim CTRL, and datasplit Test ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T89, stim CTRL, and datasplit Train ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T89, stim CTRL, and datasplit Test ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T90, stim CTRL, and datasplit Train ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n",
      "Generating pseudo-bulk profiles for sample Samp-T90, stim CTRL, and datasplit Test ...\n",
      "Generating random prop pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Generating single cell type dominant pseudo-bulk profiles ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Concatenating the two types of pseudo-bulk profiles ...\n",
      "Writing the pseudo-bulk profiles ...\n"
     ]
    }
   ],
   "source": [
    "ADD_PER_CELL_TYPE_NOISE = True\n",
    "N_CELLS_PER_PSEUDO_BULK = 5_000\n",
    "N_PSEUDO_BULKS_PER_CONDITION = 1_000\n",
    "\n",
    "# Unique values for experiment/perturbation/cell type\n",
    "samples = adata.obs[SAMPLE_ID_COL].unique()\n",
    "stims = adata.obs[STIM_COL].unique()\n",
    "cell_types = adata.obs[CELL_TYPE_COL].unique()\n",
    "datasplits = adata.obs[DATASPLIT_COL].unique()\n",
    "\n",
    "n_samples = len(samples)\n",
    "n_genes = len(gene_ids)\n",
    "n_cell_types = len(cell_types)\n",
    "\n",
    "# Define cell-type level noise for the generated pseudo-bulk profiles\n",
    "if ADD_PER_CELL_TYPE_NOISE:\n",
    "    # this produces a list of numpy arrays, each of length n_genes\n",
    "    # to reflect the expression noise associated with each specific cell type\n",
    "    per_cell_type_noise = [\n",
    "        np.random.lognormal(0, 0, n_genes) for i in range(n_cell_types)]\n",
    "else:\n",
    "    per_cell_type_noise = None\n",
    "\n",
    "# Generate pseudo-bulk profiles grouping by sample_id and stim\n",
    "for _sample in samples:\n",
    "    for _stim in stims:\n",
    "        for _datasplit in datasplits:\n",
    "\n",
    "            print(f\"Generating pseudo-bulk profiles for sample {_sample}, stim {_stim}, and datasplit {_datasplit} ...\")\n",
    "            \n",
    "            ## Subset adata to the current sample, stim and train/test split\n",
    "            subset_idx = np.where(\n",
    "                np.logical_and.reduce((\n",
    "                    adata.obs[SAMPLE_ID_COL] == _sample, \n",
    "                    adata.obs[STIM_COL] == _stim,\n",
    "                    adata.obs[DATASPLIT_COL] == _datasplit\n",
    "                ))\n",
    "            )[0]\n",
    "            \n",
    "            if len(subset_idx) == 0:\n",
    "                continue\n",
    "            subset_adata = adata[subset_idx, :]\n",
    "\n",
    "            print(\"Generating random prop pseudo-bulk profiles ...\")\n",
    "            random_prop_pb_outputs = sc_preprocess.make_prop_and_sum(\n",
    "                in_adata=subset_adata,\n",
    "                # the number of pseudo-bulk profiles to generate\n",
    "                num_samples=N_PSEUDO_BULKS_PER_CONDITION,\n",
    "                # the number of cells included/sampled when generating each pseudo-bulk profile\n",
    "                num_cells=N_CELLS_PER_PSEUDO_BULK,\n",
    "                # pseudo-bulk profiles will be generated with random proportions\n",
    "                use_true_prop=False,\n",
    "                # apply the per cell type noise\n",
    "                cell_noise=per_cell_type_noise,\n",
    "                # no sample noise\n",
    "                useSampleNoise=False,\n",
    "            )\n",
    "\n",
    "            count_df, pb_df, test_count_df, test_pb_df = random_prop_pb_outputs\n",
    "            # divide the count matrix by the sum of each row to get proportions\n",
    "            prop_df = count_df.div(count_df.sum(axis=1), axis=0)\n",
    "            test_prop_df = test_count_df.div(test_count_df.sum(axis=1), axis=0)\n",
    "\n",
    "            del count_df\n",
    "            del test_count_df\n",
    "\n",
    "            n_random_prop_pbs = len(pb_df)\n",
    "\n",
    "            print(\"Generating single cell type dominant pseudo-bulk profiles ...\")\n",
    "\n",
    "            # Generate pseudo-bulk profiles where a single cell type dominates\n",
    "            # this will produce num_samp * n_cell_types pseudo-bulk profiles\n",
    "            ct_prop_df = sc_preprocess.get_single_celltype_prop_matrix(\n",
    "                num_samp=100, #  generate 100 per cell type\n",
    "                cell_order=cell_types\n",
    "            )\n",
    "\n",
    "            # Use proportion matrix to generate pseudo-bulk profiles\n",
    "            sc_prop_df, sc_pb_df, _ = sc_preprocess.use_prop_make_sum(\n",
    "                in_adata=subset_adata,\n",
    "                num_cells=N_CELLS_PER_PSEUDO_BULK,\n",
    "                # use the generated single cell type dominant proportion matrix\n",
    "                props_vec=ct_prop_df,\n",
    "                # apply the same per cell type noise used for random prop pseudo-bulk profiles\n",
    "                cell_noise=per_cell_type_noise,\n",
    "                # no sample noise\n",
    "                sample_noise=None,\n",
    "                useSampleNoise=False\n",
    "            )\n",
    "\n",
    "            n_single_celltype_pbs = len(sc_pb_df)\n",
    "\n",
    "            print('Concatenating the two types of pseudo-bulk profiles ...')\n",
    "            prop_df =  pd.concat([prop_df, sc_prop_df])\n",
    "            pb_df = pd.concat([pb_df, sc_pb_df])\n",
    "\n",
    "            n_total_pbs = n_random_prop_pbs + n_single_celltype_pbs\n",
    "\n",
    "            metadata_df = pd.DataFrame(\n",
    "                data = {\"sample_id\":[_sample]*n_total_pbs,\n",
    "                        \"stim\":[_stim]*n_total_pbs,\n",
    "                        \"isTraining\":[_datasplit]*n_total_pbs,\n",
    "                        \"cell_prop_type\":['random']*n_random_prop_pbs + ['single_celltype']*n_single_celltype_pbs,\n",
    "                        \"samp_type\":['sc_ref']*n_total_pbs}\n",
    "                        )\n",
    "            \n",
    "            print(\"Writing the pseudo-bulk profiles ...\")\n",
    "            pseudobulk_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_pseudo_splits.pkl'\n",
    "            prop_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_prop_splits.pkl'\n",
    "            meta_file = SC_AUGMENTED_DATA_PATH / f'{STUDY_GEO_ID}_{_sample}_{_stim}_{_datasplit}_meta_splits.pkl'\n",
    "\n",
    "            pickle.dump( prop_df, open( prop_file, \"wb\" ) )\n",
    "            pickle.dump( pb_df, open( pseudobulk_file, \"wb\" ) )\n",
    "            pickle.dump( metadata_df, open( meta_file, \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buddi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
