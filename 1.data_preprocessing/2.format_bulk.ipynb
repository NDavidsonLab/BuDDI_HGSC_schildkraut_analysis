{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook formats the bulk RNAseq expression data to match the metadata fields from the generatedpseudobulks\n",
    "\n",
    "Intended inputs to this dataset are paired `.tsv` expression and metadata files\n",
    "\n",
    "The end product of this notebook will a single `.h5ad` file that includes all bulk obervations and the following metadata fields:\n",
    "- stimulation column `stim`\n",
    "- sample id column `sample_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import yaml\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ID_COL = 'sample_id'\n",
    "STIM_COL = 'stim'\n",
    "\n",
    "GENE_ID_COL = 'gene_ids'\n",
    "\n",
    "DATASPLIT_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config\n",
    "The config file specifies the path to data and software repo (due to currently in active development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root directory of the analysis repository\n",
    "REPO_ROOT = subprocess.run(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "REPO_ROOT = pathlib.Path(REPO_ROOT)\n",
    "\n",
    "CONFIG_FILE = REPO_ROOT / 'config.yml'\n",
    "assert CONFIG_FILE.exists(), f\"Config file not found at {CONFIG_FILE}\"\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as file:\n",
    "    config_dict = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dev buddi fork to path and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buddi_fork_path = config_dict['software_path']['buddi_HGSC']\n",
    "buddi_fork_path = pathlib.Path(buddi_fork_path)\n",
    "assert buddi_fork_path.exists(), f\"buddi fork not found at {buddi_fork_path}\"\n",
    "\n",
    "sys.path.insert(0, str(buddi_fork_path))\n",
    "# this is quite ugly, once activate modifications are done this will be changed\n",
    "# to a proper installation + import\n",
    "from buddi import preprocessing\n",
    "from buddi.preprocessing import utils\n",
    "from buddi.preprocessing import generate_pseudo_bulks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Path to Processed Bulk RNA-seq Data and relevant Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BULK_DATA_PATH = pathlib.Path(config_dict['data_path']['bulk_data_path'])\n",
    "BULK_BLACK_TSV_FILE = BULK_DATA_PATH / 'supp_table_6_black_expr.tsv'\n",
    "assert BULK_BLACK_TSV_FILE.exists(), f\"Black bulk expression data file not found at {BULK_BLACK_TSV_FILE}\"\n",
    "BULK_WHITE_TSV_FILE = BULK_DATA_PATH / 'supp_table_7_white_expr.tsv'\n",
    "assert BULK_WHITE_TSV_FILE.exists(), f\"White bulk expression data file not found at {BULK_WHITE_TSV_FILE}\"\n",
    "\n",
    "BULK_BLACK_METADATA_FILE = BULK_DATA_PATH / 'supp_table_3_main_black_metadata_table.tsv'\n",
    "assert BULK_BLACK_METADATA_FILE.exists(), f\"Black bulk metadata file not found at {BULK_BLACK_METADATA_FILE}\"\n",
    "BULK_WHITE_METADATA_FILE = BULK_DATA_PATH / 'supp_table_4_main_white_metadata_table.tsv'\n",
    "assert BULK_WHITE_METADATA_FILE.exists(), f\"White bulk metadata file not found at {BULK_WHITE_METADATA_FILE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path to write Pre-Processing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_OUTPUT_PATH = REPO_ROOT / 'processed_data'\n",
    "assert PREPROCESSING_OUTPUT_PATH.exists(), f\"Preprocessing output path {PREPROCESSING_OUTPUT_PATH} does not exist\"\n",
    "BULK_FORMAT_DATA_PATH = PREPROCESSING_OUTPUT_PATH / 'bulk_formatted'\n",
    "BULK_FORMAT_DATA_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "BULK_FORMAT_EXPR_FILE = BULK_FORMAT_DATA_PATH / 'schildkraut_bulk_processed.h5ad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Bulk Data\n",
    "### Load and Preprocess tsv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_expr_df = pd.DataFrame()\n",
    "bulk_metadata_df = pd.DataFrame()\n",
    "\n",
    "for stim, expr_file, metadata_file in zip(\n",
    "    ['black', 'white'],\n",
    "    [BULK_BLACK_TSV_FILE, BULK_WHITE_TSV_FILE], \n",
    "    [BULK_BLACK_METADATA_FILE, BULK_WHITE_METADATA_FILE]):\n",
    "\n",
    "    # Load the expression data\n",
    "\n",
    "    # Data is originally in the format of genes x samples\n",
    "    expr_df = pd.read_csv(expr_file, sep='\\t', index_col=0)\n",
    "    expr_df = expr_df.T # Transpose to samples x genes\n",
    "    expr_df.dropna() # Drop any rows with missing values\n",
    "    expr_df.index = expr_df.index.str.replace('Sample_', '', regex=False) # Remove the 'Sample_' prefix from the sample IDs\n",
    "\n",
    "    # Load the metadata\n",
    "    metadata_df = pd.read_csv(metadata_file, sep='\\t', index_col=0)\n",
    "\n",
    "    # Subset to only the samples that have both expression and metadata\n",
    "    overlapping_rows = expr_df.index.intersection(metadata_df.index)\n",
    "    expr_df = expr_df.loc[overlapping_rows]\n",
    "    metadata_df = metadata_df.loc[overlapping_rows]\n",
    "\n",
    "    # Add the stim column\n",
    "    metadata_df[STIM_COL] = stim\n",
    "\n",
    "    bulk_expr_df = pd.concat([bulk_expr_df, expr_df])\n",
    "    bulk_metadata_df = pd.concat([bulk_metadata_df, metadata_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 18983)\n",
      "(588, 18509)\n",
      "(588, 20)\n"
     ]
    }
   ],
   "source": [
    "print(bulk_expr_df.shape)\n",
    "# drop any columns with missing values to remove genes not shared between the two datasets\n",
    "bulk_expr_df = bulk_expr_df.dropna(axis=1)\n",
    "print(bulk_expr_df.shape)\n",
    "\n",
    "print(bulk_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create anndata object and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(X=bulk_expr_df, obs=bulk_metadata_df)\n",
    "\n",
    "adata.var[GENE_ID_COL] = adata.var.index.tolist()\n",
    "adata.obs[SAMPLE_ID_COL] = adata.obs.index.tolist()\n",
    "\n",
    "for col in adata.obs.columns:\n",
    "    if adata.obs[col].dtype == object or adata.obs[col].dtype == \"category\":\n",
    "        adata.obs[col] = adata.obs[col].astype(\"str\")\n",
    "\n",
    "adata.write(BULK_FORMAT_EXPR_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_out_file = BULK_FORMAT_DATA_PATH / f'schildkraut_genes.pkl'\n",
    "gene_ids = adata.var[GENE_ID_COL]\n",
    "pickle.dump(gene_ids, open( gene_out_file, \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_scanpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
